### Parcial Paradigmas

# Punto #1

# Diagramas de Flujo: Paradigmas de ProgramaciÃ³n Concurrente y CÃ¡lculo PI

## IntroducciÃ³n

Este repositorio contiene dos diagramas de flujo que comparan dos paradigmas de programaciÃ³n distintos para resolver el problema de **RegresiÃ³n Lineal Distribuida**. Los diagramas muestran cÃ³mo cada paradigma aborda la ejecuciÃ³n paralela de tareas y la comunicaciÃ³n entre procesos.

---

## Â¿Por quÃ© estos dos paradigmas?

Cuando quieres que mÃºltiples tareas se ejecuten "al mismo tiempo", tienes al menos dos formas principales de hacerlo:

1. **ProgramaciÃ³n Concurrente**: Varias tareas comparten recursos (memoria, datos) y el programa informa quÃ© estÃ¡ pasando en cada momento.
2. **CÃ¡lculo PI**: Varios procesos completamente independientes que solo se comunican a travÃ©s de "canales" especiales (como si fueran telÃ©fonos dedicados).

---

## ğŸ“Š Diagrama 1: Paradigma de ProgramaciÃ³n Concurrente

### Â¿QuÃ© es?

La **programaciÃ³n concurrente** es un estilo donde el programa principal crea varias tareas que se ejecutan "casi al mismo tiempo". Cada tarea puede acceder a datos compartidos y el programa va informando sobre el progreso de cada una.

**Es como una fÃ¡brica donde:**
- El gerente (programa principal) crea 3 grupos de obreros
- Todos trabajan en el mismo espacio (comparten recursos)
- El gerente constantemente chequea quÃ© estÃ¡ haciendo cada grupo
- Cuando todos terminan, el gerente combina los resultados

### CaracterÃ­sticas Principales

| CaracterÃ­stica | ExplicaciÃ³n |
|---|---|
| **3 Tareas simultÃ¡neas** | Tarea 1, Tarea 2 y Tarea 3 se ejecutan al mismo tiempo |
| **Memoria compartida** | Las tareas pueden acceder a los mismos datos |
| **SincronizaciÃ³n explÃ­cita** | Hay un contador que verifica cuÃ¡ndo todas terminan |
| **Informes constantes** | El programa imprime quÃ© estÃ¡ haciendo cada tarea |
| **Orden finalmente secuencial** | Los resultados se combinan en orden al final |

### Flujo Paso a Paso

```
1. INICIO
   â””â”€ El programa imprime: "Sistema iniciado"

2. CREACIÃ“N
   â””â”€ Se crean 3 tareas
   â””â”€ El programa imprime: "Creando tareas..."
   â””â”€ Inicializar contador en 0

3. EJECUCIÃ“N PARALELA (Las 3 tareas avanzan simultÃ¡neamente)

   Tarea 1:                          Tarea 2:                          Tarea 3:
   - Procesar datos A    |           - Procesar datos B    |           - Procesar datos C
   - Calcular            |           - Calcular            |           - Calcular
   - Reportar progreso   |           - Reportar progreso   |           - Reportar progreso
   - Incrementar contador|           - Incrementar contador|           - Incrementar contador

4. SINCRONIZACIÃ“N
   â””â”€ Esperar a que contador llegue a 3
   â””â”€ El programa verifica: Â¿contador == 3?

5. COMBINACIÃ“N
   â”œâ”€ Si SÃ: Combinar resultados de las 3 tareas
   â”‚         Mostrar resultado final
   â”‚         Liberar recursos
   â”‚         Imprime: "Sistema finalizado"
   â”‚
   â””â”€ Si NO: Manejar error
            Imprime: "ERROR: Tareas incompletas"

6. FIN
```

### Ventajas

âœ… **Simple de entender**: Es como tareas trabajando en paralelo  
âœ… **Buena para datos compartidos**: Las tareas pueden acceder a los mismos datos  
âœ… **FÃ¡cil de depurar**: Se puede ver el progreso de cada tarea  

### Desventajas

âŒ **Limitado en escalabilidad**: Compartir mucha memoria es problemÃ¡tico con muchas tareas  
âŒ **Problemas de sincronizaciÃ³n**: Riesgo de que dos tareas modifiquen los mismos datos  
âŒ **DifÃ­cil de predecir**: El orden de ejecuciÃ³n puede variar  

### Ejemplo de Salida en Consola

```
Sistema iniciado
Creando tareas...
Tarea 1 iniciada
Tarea 2 iniciada
Tarea 3 iniciada
Tarea 1 ejecutando...
Tarea 2 ejecutando...
Tarea 3 ejecutando...
Tarea 1 en progreso 50%
Tarea 3 en progreso 50%
Tarea 2 en progreso 50%
Tarea 1 completada
Tarea 2 completada
Tarea 3 completada
Recolectando resultados...
Combinando datos...
Resultado Final: [dato1 + dato2 + dato3]
Tiempo total: 2.5 segundos
Sistema finalizado exitosamente
```

---

## ğŸ“Š Diagrama 2: Paradigma de ProgramaciÃ³n CÃ¡lculo PI

### Â¿QuÃ© es?

El **CÃ¡lculo PI** es un modelo teÃ³rico de programaciÃ³n donde tenemos **procesos completamente independientes** que se comunican exclusivamente a travÃ©s de **canales**. Los procesos no comparten memoria, solo intercambian mensajes.

**Es como un centro de llamadas donde:**
- Hay 1 coordinador y 3 agentes de ventas
- Cada agente tiene su propio telÃ©fono (canal)
- El coordinador solo se comunica por telÃ©fono
- Los agentes solo hacen caso cuando reciben una llamada
- Al terminar, reportan por su telÃ©fono

### CaracterÃ­sticas Principales

| CaracterÃ­stica | ExplicaciÃ³n |
|---|---|
| **1 Coordinador + 3 Trabajadores** | Procesos completamente independientes |
| **4 Canales privados** | canal_datos, canal_gradientes, canal_parametros, canal_control |
| **ComunicaciÃ³n por mensajes** | Solo se comunican a travÃ©s de canales |
| **SincronizaciÃ³n implÃ­cita** | Los canales sincronizan automÃ¡ticamente |
| **Mayor escalabilidad** | FÃ¡cil agregar mÃ¡s procesos |
| **Sin memoria compartida** | Cada proceso tiene sus propios datos |

### Flujo Paso a Paso

```
1. INICIO
   â””â”€ Sistema imprime: "Sistema CÃ¡lculo PI iniciado"

2. CREACIÃ“N DE PROCESOS Y CANALES
   â”œâ”€ Crear 1 proceso coordinador
   â”œâ”€ Crear 3 procesos trabajadores
   â””â”€ Crear 4 canales privados:
      â”œâ”€ canal_datos (para distribuir datos)
      â”œâ”€ canal_parametros (para enviar parÃ¡metros)
      â”œâ”€ canal_gradientes (para recibir resultados)
      â””â”€ canal_control (para seÃ±ales)

3. INICIALIZACIÃ“N
   â”œâ”€ Coordinador crea parÃ¡metros iniciales: Î¸ = [0.5, 0.3]
   â”œâ”€ Coordinador envÃ­a datos por canal_datos
   â”œâ”€ Los trabajadores reciben EN ESPERA del canal_datos:
   â”‚  â”œâ”€ Trabajador 1 recibe particiÃ³n 1
   â”‚  â”œâ”€ Trabajador 2 recibe particiÃ³n 2
   â”‚  â””â”€ Trabajador 3 recibe particiÃ³n 3
   â””â”€ El programa reporta lo que pasa

4. DISTRIBUCIÃ“N DE PARÃMETROS INICIALES
   â”œâ”€ Coordinador envÃ­a Î¸ por canal_parametros
   â”œâ”€ Cada trabajador recibe EN ESPERA:
   â”‚  â”œâ”€ Trabajador 1: "Î¸ recibido"
   â”‚  â”œâ”€ Trabajador 2: "Î¸ recibido"
   â”‚  â””â”€ Trabajador 3: "Î¸ recibido"
   â””â”€ Los trabajadores estÃ¡n listos para trabajar

5. CICLO PRINCIPAL (se repite varias veces)

   FASE A - CÃLCULO EN PARALELO:
   (Los 3 trabajadores calculan al mismo tiempo)

   Trabajador 1:                     Trabajador 2:                     Trabajador 3:
   - Calcular âˆ‡fâ‚ = [0.2, 0.1]  |   - Calcular âˆ‡fâ‚‚ = [0.15, 0.12] |   - Calcular âˆ‡fâ‚ƒ = [0.25, 0.08]
   - EnvÃ­a por canal_gradientes  |   - EnvÃ­a por canal_gradientes  |   - EnvÃ­a por canal_gradientes
   - Espera nuevo mensaje        |   - Espera nuevo mensaje        |   - Espera nuevo mensaje

   FASE B - AGREGACIÃ“N EN COORDINADOR:
   â”œâ”€ Coordinador espera 3 gradientes en canal_gradientes
   â”œâ”€ Recibe âˆ‡fâ‚ de Trabajador 1
   â”œâ”€ Recibe âˆ‡fâ‚‚ de Trabajador 2
   â”œâ”€ Recibe âˆ‡fâ‚ƒ de Trabajador 3
   â””â”€ Imprime: "Los 3 gradientes recibidos"

   FASE C - ACTUALIZACIÃ“N EN COORDINADOR:
   â”œâ”€ Calcular promedio: âˆ‡f_prom = (âˆ‡fâ‚+âˆ‡fâ‚‚+âˆ‡fâ‚ƒ)/3 = [0.20, 0.10]
   â”œâ”€ Actualizar: Î¸_nuevo = Î¸ - Î± Ã— âˆ‡f_prom = [0.48, 0.29]
   â”œâ”€ Verificar convergencia: Â¿||Î¸_nuevo - Î¸|| < Îµ?
   â””â”€ Imprime: "ParÃ¡metros actualizados"

6. DECISIÃ“N DE CONVERGENCIA

   â”œâ”€ Si SÃ convergiÃ³:
   â”‚  â”œâ”€ Enviar STOP por canal_control a todos
   â”‚  â”œâ”€ Todos los trabajadores reciben STOP y finalizan
   â”‚  â”œâ”€ Coordinador muestra parÃ¡metros finales
   â”‚  â””â”€ Imprime: "Convergencia alcanzada"
   â”‚
   â””â”€ Si NO convergiÃ³:
      â”œâ”€ Enviar CONTINUAR por canal_control
      â”œâ”€ Enviar Î¸_nuevo por canal_parametros
      â”œâ”€ Los trabajadores despiertan y calculan de nuevo
      â””â”€ Vuelven a FASE A (CÃ¡lculo en paralelo)

7. FIN
   â””â”€ Cuando converge: "Sistema finalizado exitosamente"
```

### Ventajas

âœ… **Altamente escalable**: Puedes agregar mÃ¡s procesos sin problemas  
âœ… **Sin conflictos de memoria**: Cada proceso tiene sus propios datos  
âœ… **FÃ¡cil de razonar**: La comunicaciÃ³n es explÃ­cita y clara  
âœ… **Seguro**: Un proceso no puede interferir con otro  

### Desventajas

âŒ **MÃ¡s abstracto**: Es mÃ¡s difÃ­cil de entender que la concurrencia simple  
âŒ **Overhead de canales**: MÃ¡s lento que compartir memoria directamente  
âŒ **Mayor complejidad**: Hay que diseÃ±ar bien los canales  

### Ejemplo de Salida en Consola

```
Sistema CÃ¡lculo PI iniciado
Canales creados:
- canal_datos
- canal_gradientes
- canal_parametros
- canal_control
Coordinador: ParÃ¡metros iniciales Î¸ = [0.5, 0.3]
Coordinador: Enviando particiones a los 3 trabajadores
Trabajador 1: Datos recibidos
Trabajador 2: Datos recibidos
Trabajador 3: Datos recibidos
Coordinador: Enviando parÃ¡metros iniciales
Trabajador 1: Î¸ recibido = [0.5, 0.3]
Trabajador 2: Î¸ recibido = [0.5, 0.3]
Trabajador 3: Î¸ recibido = [0.5, 0.3]

--- ITERACIÃ“N 1 ---
Trabajador 1: Calculando âˆ‡fâ‚ = [0.2, 0.1]
Trabajador 2: Calculando âˆ‡fâ‚‚ = [0.15, 0.12]
Trabajador 3: Calculando âˆ‡fâ‚ƒ = [0.25, 0.08]
Trabajador 1: Gradiente enviado
Trabajador 2: Gradiente enviado
Trabajador 3: Gradiente enviado
Coordinador: Esperando 3 gradientes...
Coordinador: Recibido âˆ‡fâ‚ de Trabajador 1
Coordinador: Recibido âˆ‡fâ‚‚ de Trabajador 2
Coordinador: Recibido âˆ‡fâ‚ƒ de Trabajador 3
Coordinador: âˆ‡f_prom = [0.20, 0.10]
Coordinador: Actualizando Î¸
Coordinador: Î¸_nuevo = [0.48, 0.29]
Coordinador: Verificar convergencia
Coordinador: Enviando CONTINUAR a Trabajadores
Coordinador: Broadcast de nuevos parÃ¡metros

--- ITERACIÃ“N 2 ---
[Repite el proceso...]

--- CONVERGENCIA ALCANZADA ---
Coordinador: Convergencia alcanzada
Coordinador: Enviando STOP a Trabajadores
Trabajador 1: Finalizando...
Trabajador 2: Finalizando...
Trabajador 3: Finalizando...
ParÃ¡metros finales: Î¸ = [0.48, 0.29]
Iteraciones completadas: 5
Sistema finalizado exitosamente
```

---

## ğŸ”„ ComparaciÃ³n Lado a Lado

### Concurrencia vs CÃ¡lculo PI

| Aspecto | Concurrencia | CÃ¡lculo PI |
|--------|-------------|-----------|
| **Estructura** | Tareas con memoria compartida | Procesos independientes con canales |
| **ComunicaciÃ³n** | Variables compartidas + informes | Solo mensajes en canales |
| **SincronizaciÃ³n** | ExplÃ­cita (contador, locks) | ImplÃ­cita (espera de mensajes) |
| **Escalabilidad** | Limitada | Muy buena |
| **Complejidad** | Simple | Media-Alta |
| **Seguridad** | Riesgo de conflictos | Muy segura |
| **Performance** | MÃ¡s rÃ¡pida (sin overhead) | Puede ser mÃ¡s lenta (overhead de canales) |
| **Uso ideal** | Tareas con datos compartidos | Sistemas distribuidos |

---

## ğŸ’¡ AnalogÃ­as para Entender Mejor

### ProgramaciÃ³n Concurrente = Equipo en una Oficina

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     OFICINA (Memoria Compartida)    â”‚
â”‚                                      â”‚
â”‚  Persona 1      Persona 2   Persona 3â”‚
â”‚   [Working]      [Working]   [Working]â”‚
â”‚     en A           en B         en C â”‚
â”‚                                      â”‚
â”‚  Jefe: "Â¿DÃ³nde van?"                â”‚
â”‚  Jefe: "Persona 1 42% hecha"        â”‚
â”‚  Jefe: "Persona 2 completada"       â”‚
â”‚  Jefe: "Esperando Persona 3..."     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Todos usan el mismo espacio y herramientas.
El jefe constantemente chequea quÃ© hace cada uno.
```

### CÃ¡lculo PI = Centro de Llamadas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         Canales         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Coordinador â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚Trabajador 1â”‚
â”‚            â”‚ "AquÃ­ estÃ¡n tus datos"  â”‚            â”‚
â”‚            â”‚                         â”‚ "Listo"    â”‚
â”‚            |<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚            â”‚ "Calcula el gradiente"  â”‚            â”‚
â”‚            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚            â”‚
â”‚            â”‚                         â”‚ Calculando â”‚
â”‚            â”‚ "EnvÃ­a el resultado"    â”‚            â”‚
â”‚            â”‚                         â”‚ âˆ‡fâ‚ enviadoâ”‚
â”‚            â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Similar con Trabajador 2 y 3 por canales separados.

Cada uno tiene su telÃ©fono (canal).
Solo se comunican por telÃ©fono.
El coordinador no ve quÃ© hacen, solo recibe mensajes.
```

---

## ğŸ¯ Casos de Uso

### Usa Concurrencia cuando:
- Las tareas necesitan compartir muchos datos
- El problema es relativamente simple
- Ejecutas en una sola mÃ¡quina
- El rendimiento es crÃ­tico (sin overhead de canales)

### Usa CÃ¡lculo PI cuando:
- Quieres mÃ¡xima modularidad y escalabilidad
- Tienes muchos procesos independientes
- Trabajas en sistemas distribuidos (mÃºltiples mÃ¡quinas)
- Quieres evitar problemas de sincronizaciÃ³n compleja
- Necesitas garantÃ­as de seguridad (un proceso no afecta a otro)

---

## ğŸ“ CÃ³mo Leer los Diagramas

### Para el diagrama Concurrente:

1. **Sigue la lÃ­nea de arriba a abajo**
2. **Cuando veas `fork`**: Las tareas ahora van en paralelo (lee los 3 brazos simultÃ¡neamente)
3. **Lee las notas**: Esas son las cosas que el programa imprime
4. **Cuando regresa a una lÃ­nea**: Los procesos se sincronizaron (se esperaron mutuamente)
5. **El `if`**: Es la decisiÃ³n: Â¿Todas completaron? SÃ­ o No

### Para el diagrama CÃ¡lculo PI:

1. **Sigue de arriba a abajo como antes**
2. **Cuando veas `fork`**: Los procesos avanzan en paralelo
3. **Las acciones de cada proceso**: Esperar, Calcular, Enviar (por sus canales)
4. **Las notas**: QuÃ© se imprime en consola (para debugging)
5. **DespuÃ©s del fork**: El coordinador recolecta todos los mensajes
6. **El `if`**: DecisiÃ³n: Â¿ConvergiÃ³? SÃ­ â†’ STOP. No â†’ CONTINUAR

---

## ğŸš€ PrÃ³ximos Pasos

Para implementar estos diseÃ±os, necesitarÃ­as:

### ProgramaciÃ³n Concurrente:
- Usar `threads` en Java, Python (`threading`), C++ (`pthread`)
- Usar `locks` o `mutex` para sincronizaciÃ³n
- Usar contadores o `barriers` para esperar tareas

### CÃ¡lculo PI:
- Usar un lenguaje que soporte paso de mensajes:
  - Erlang, Go, Akka, MPI (para paralelo)
  - O implementar con sockets/HTTP para sistemas distribuidos

---

## ğŸ“š Recursos para Aprender MÃ¡s

### ProgramaciÃ³n Concurrente:
- "The Art of Multiprocessor Programming" - Herlihy & Shavit
- DocumentaciÃ³n oficial de threading en tu lenguaje

### CÃ¡lculo PI:
- "Communicating Sequential Processes" - Tony Hoare (CSP)
- DocumentaciÃ³n de Erlang o Go para ejemplos prÃ¡cticos

---

## â“ Preguntas Frecuentes

**P: Â¿CuÃ¡l es mÃ¡s rÃ¡pido?**  
R: Concurrencia es generalmente mÃ¡s rÃ¡pida (menos overhead), pero CÃ¡lculo PI es mÃ¡s escalable.

**P: Â¿Puedo usar ambos juntos?**  
R: SÃ­, muchos sistemas usan concurrencia dentro de procesos y CÃ¡lculo PI entre procesos.

**P: Â¿Es CÃ¡lculo PI solo teorÃ­a?**  
R: No, lenguajes como Erlang y Go lo implementan en la prÃ¡ctica.

**P: Â¿Por quÃ© se llama "CÃ¡lculo PI"?**  
R: Porque el sÃ­mbolo Ï€ se usa para representar procesos (del griego "proceso").

---

## ğŸ“„ Estructura del Repositorio

```
.
â”œâ”€â”€ README.md                          (este archivo)
â”œâ”€â”€ diagrama_concurrente_CORREGIDO.puml (Diagrama 1)
â”œâ”€â”€ diagrama_pi_CORREGIDO.puml         (Diagrama 2)
â”œâ”€â”€ ejemplos/
â”‚   â”œâ”€â”€ concurrencia_python.py         (Ejemplo en Python)
â”‚   â”œâ”€â”€ calculus_pi_go.go              (Ejemplo en Go)
â”‚   â””â”€â”€ README_ejemplos.md
â””â”€â”€ recursos/
    â”œâ”€â”€ refencias_teoricas.md
    â””â”€â”€ enlaces_utiles.md
```

---

## ğŸ‘¤ Autor

Documento de referencia para estudiantes de paradigmas de programaciÃ³n.

## ğŸ“„ Licencia

Libre para usar con propÃ³sitos educativos.

---

## ğŸ“ Dudas o Sugerencias

Si hay algo que no entiendes o quieres mÃ¡s detalle sobre algÃºn aspecto, consulta las secciones correspondientes de este README.

**Recuerda:** La programaciÃ³n concurrente es complicada. TÃ³mate tu tiempo para entenderla bien.
